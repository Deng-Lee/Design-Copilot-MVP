import os
import sys

# 1. å¼ºåˆ¶è®¾ç½®é•œåƒ (å¿…é¡»åŠ ï¼Œå¦åˆ™åŠ è½½ BAAI æ¨¡å‹å¯èƒ½ä¼šè”ç½‘æŠ¥é”™)
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

try:
    from langchain_classic.chains import create_retrieval_chain
    from langchain_classic.chains.combine_documents import create_stuff_documents_chain
except ImportError:
    print("âŒ é”™è¯¯: æœªæ‰¾åˆ° langchain-classic åŒ…ã€‚")
    print("ğŸ‘‰ è¯·è¿è¡Œ: pip install langchain-classic")
    sys.exit(1)

# åŠ è½½ç¯å¢ƒå˜é‡ (è¯»å– API Key)
load_dotenv("../.env")

# ================= é…ç½®åŒºåŸŸ =================

# 1. æ•°æ®åº“è·¯å¾„ (å¿…é¡»ä¸ ingest.py é‡Œçš„ PERSIST_DIRECTORY å®Œå…¨ä¸€è‡´)
current_dir = os.path.dirname(os.path.abspath(__file__))
PERSIST_DIRECTORY = os.path.join(current_dir, "chroma_db")

# 2. Embedding æ¨¡å‹ (å¿…é¡»ä¸ ingest.py é‡Œçš„æ¨¡å‹å®Œå…¨ä¸€è‡´)
# ä½ åˆšæ‰ç”¨çš„æ˜¯è¿™ä¸ªä¸­æ–‡æ¨¡å‹ï¼Œè¿™é‡Œè¯»å–æ—¶å¿…é¡»ç”¨åŒä¸€ä¸ª
EMBEDDING_MODEL_NAME = "BAAI/bge-small-zh-v1.5"

# 3. å¤§æ¨¡å‹é…ç½® (è¿™é‡Œé»˜è®¤ä½¿ç”¨ DeepSeek APIï¼Œæ•ˆæœæœ€å¥½)
# å¦‚æœä½ æƒ³ç”¨æœ¬åœ° Ollamaï¼Œè¯·çœ‹ä»£ç åº•éƒ¨çš„æ³¨é‡Šè¿›è¡Œä¿®æ”¹
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY") or "ä½ çš„sk-xxxxxxxx" 

# ===========================================

def main():
    # --- 1. å‡†å¤‡â€œé’¥åŒ™â€ (Embedding) ---
    print(f"ğŸ”‘ æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹: {EMBEDDING_MODEL_NAME}...")
    try:
        embedding = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ æç¤º: å¦‚æœæ˜¯ç½‘ç»œé—®é¢˜ï¼Œè¯·æ£€æŸ¥ HF_ENDPOINT è®¾ç½®æˆ–å°è¯•æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹ã€‚")
        return

    # --- 2. æ‰“å¼€â€œä»“åº“â€ (ChromaDB) ---
    if not os.path.exists(PERSIST_DIRECTORY):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶å¤¹ {PERSIST_DIRECTORY}")
        print("ğŸ‘‰ è¯·å…ˆè¿è¡Œ ingest.py ç”Ÿæˆæ•°æ®ï¼")
        return

    vector_db = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=embedding
    )
    retriever = vector_db.as_retriever(search_kwargs={"k": 3})
    print(f"ğŸ“š æˆåŠŸè¿æ¥æ•°æ®åº“ï¼Œå½“å‰åŒ…å« {vector_db._collection.count()} æ¡çŸ¥è¯†ç‰‡æ®µ")

    # --- 3. å”¤é†’â€œå¤§è„‘â€ (LLM) ---
    print("ğŸ¤– æ­£åœ¨è¿æ¥ DeepSeek å¤§æ¨¡å‹...")
    llm = ChatOpenAI(
        model="deepseek-chat", 
        api_key=DEEPSEEK_API_KEY, 
        base_url="https://api.deepseek.com",
        temperature=0.1 # å†™ä»£ç éœ€è¦ä¸¥è°¨ï¼Œæ¸©åº¦è®¾ä½ä¸€ç‚¹
    )

    # --- 4. è®¾å®šâ€œæŒ‡ä»¤â€ (Prompt) ---
    # è¿™æ˜¯ RAG çš„æ ¸å¿ƒï¼šå‘Šè¯‰æ¨¡å‹â€œå‚è€ƒä¸‹é¢çš„ Context æ¥å›ç­” Questionâ€
    prompt = ChatPromptTemplate.from_template("""
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„å‰ç«¯å¼€å‘ä¸“å®¶ (Design Copilot)ã€‚
    è¯·æ ¹æ®ä»¥ä¸‹ <context> æ ‡ç­¾ä¸­çš„å‚è€ƒæ–‡æ¡£ï¼Œå›ç­”ç”¨æˆ·çš„ <input>ã€‚
    
    <context>
    {context}
    </context>
    
    <input>
    {input}
    </input>

    ã€å›ç­”è¦æ±‚ã€‘ï¼š
    1. å¿…é¡»ä¼˜å…ˆä½¿ç”¨å‚è€ƒæ–‡æ¡£ä¸­æä¾›çš„ç»„ä»¶ API å’Œä»£ç é£æ ¼ã€‚
    2. å¦‚æœå‚è€ƒæ–‡æ¡£æœ‰ç›¸å…³ä»£ç ï¼Œç›´æ¥ç»™å‡ºå®Œæ•´çš„ã€å¯è¿è¡Œçš„ä»£ç ç¤ºä¾‹ã€‚
    3. å¦‚æœæ–‡æ¡£é‡Œæ²¡æåˆ°çš„å±æ€§ï¼Œä¸è¦çç¼–ã€‚
    """)

    question_answer_chain = create_stuff_documents_chain(llm, prompt)
    
    # æ­¥éª¤ B: åˆ›å»ºâ€œæ£€ç´¢é“¾â€
    # å®ƒçš„ä½œç”¨æ˜¯ï¼šæ‹¿åˆ°ç”¨æˆ·é—®é¢˜ -> è°ƒç”¨ retriever -> æ‹¿åˆ°ç›¸å…³æ–‡æ¡£ -> ä¼ ç»™ä¸Šé¢çš„ question_answer_chain
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)

    # --- 6. äº¤äº’å¾ªç¯ ---
    print("\nâœ… Design Copilot å·²å°±ç»ªï¼(è¾“å…¥ 'exit' é€€å‡º)")
    while True:
        user_input = input("\nğŸ‘‰ è¯·è¾“å…¥éœ€æ±‚: ")
        if user_input.lower() in ["exit", "quit", "q"]:
            break
        
        if not user_input.strip():
            continue

        print("â³ æ€è€ƒä¸­...")
        try:
            # æ‰§è¡Œé—®ç­”é“¾
            response = rag_chain.invoke({"input": user_input})
            
            print("\n" + "="*40)
            print("ğŸ¤– Copilot å›ç­”ï¼š")
            print(response["answer"])
            print("="*40)
            
            # è°ƒè¯•ï¼šçœ‹çœ‹å®ƒåˆ°åº•å‚è€ƒäº†å“ªé‡Œ
            print("\nğŸ“š å‚è€ƒæ¥æºï¼š")
            for doc in response["context"]:
                # è·å–æˆ‘ä»¬åœ¨ ingest.py é‡Œè¾›è‹¦ä¿å­˜çš„æ–‡ä»¶å metadata
                source = doc.metadata.get('source', 'æœªçŸ¥æ¥æº')
                filename = os.path.basename(source)
                print(f"- {filename}")
                
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()